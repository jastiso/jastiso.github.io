---
title: Tools - Jennifer Stiso
layout: default
---

	<div class="tools">
		<h2>Software, packages, and other tools</h2>
	
	<img src="extension_banner.PNG" class = "floatl" width="600" alt="chrome_extension">

	
		<p>	  <b>Tools Enabling Citation Transparency:</b> Some recent <a href="https://pubmed.ncbi.nlm.nih.gov/32561883/" class="ext" target="_blank">work from Jordan Dworkin</a> showed that neuroscience tends to cite men more than would be expect given thier prevalence in the field and that this trend in increasing with time. While there are <a href="https://www.sciencedirect.com/science/article/pii/S0896627320303573?casa_token=vGpjIq7DU4MAAAAA:tm-TXGJpxZ5fSYZeM3bcEmaZ-JyhhDBGJYJZnsCfqpOzs7tc0nMXRV3t8u2r0qY4uKfSZazw" class="ext" target="_blank">many courses of action</a> to help mitigate these biased citation practices, I have recently helped contribute to some tools that can help individuals quantify and offset these biases.</p>
		<p> I have developed a <a href="https://chrome.google.com/webstore/detail/citation-transparency/cepnbdbhabaljgecaddglhhcgajphbcf" class="ext" target="_blank"><b>Google Chrome extension</b></a> with Matthew Schaff that will display the probabilistic gender of first and last authors of all papers on Google Scholar or PubMed search page. The idea is that is people are consciously aware of this information as they are searching for references, they can more easily choose to cite a diverse group of scientists.</p>
		<img src="../figures/gs_ex.PNG" class="paper"><img src="../figures/pm_ex.PNG" class="paper">
		<p> I have also contributed to a project led by Dale Zhou that developed a <a href="https://github.com/dalejn/cleanBib" class="ext" target="_blank"><b>jupyter notebook</b></a> that will quantify the gender breakdown of first and last authors in a .bib file. The hope is that authors can see the gender breakdown of their citations, and then retroactively add more work from women led teams.</p>
		<p> There are a lot of limitations to these tools, the first that I notice is the lack of intersectionality. We hope to help extend these tools to race in the near future. Additionally, the classification of authors in man/woman categories imposes a false gender binary. The intent here is to capture the perceived gender of the authors, rather than reflect their true gender identity. </p>

		<p>	  <b>Python Packages:</b> Along with my colleagues <a href="https://www.lindenparkes.com/" class="ext" target="_blank">Dr. Linden Parkes</a> and <a href="https://scholar.google.com/citations?user=nLpyoNIAAAAJ&hl=en" class="ext" target="_blank">Jason Kim</a>
			I've been working on a Python package to help researchers use tools from network control theory. The package is still in its beta stages, but you can test it out 
			<a href="https://github.com/dalejn/cleanBib" class="ext" target="_blank"><b>on PyPi</b></a> and look through the <a href="https://github.com/BassettLab/control_package" class="ext" target="_blank"><b>code</b>
			 and <a href="https://control-package.readthedocs.io/en/latest/?badge=latest" class="ext" target="_blank"><b>docs.</b>  </p>

	</div>
